{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('teleCust1000t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())\n",
    "print(\"-------\")\n",
    "print(data['custcat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.savefig(\"correlation_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'custcat'\n",
    "correlations = data.corr()[target_column].sort_values(ascending=False)\n",
    "\n",
    "# Print sorted correlations\n",
    "print(\"Correlations with 'custcat':\")\n",
    "print(correlations)\n",
    "\n",
    "# Visualize the correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=correlations.index, y=correlations.values, palette='coolwarm')\n",
    "plt.title(f'Correlation of Features with {target_column}')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xlabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sort-corrolation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot histogram for 'ed'\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.histplot(data=data, x=\"ed\", palette=\"viridis\")\n",
    "plt.title(\"Histogram of 'ed'\")\n",
    "plt.xlabel(\"ed\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Plot histogram for 'tenure'\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.histplot(data=data, x=\"tenure\", palette=\"viridis\")\n",
    "plt.title(\"Histogram of 'tenure'\")\n",
    "plt.xlabel(\"tenure\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Histograms of 'ed' and 'tenure'\", y=1.02)\n",
    "plt.savefig(\"histograms.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, :-1]) \n",
    "labels = data.iloc[:, -1]  \n",
    "scaled_data = pd.DataFrame(scaled_data, columns=data.columns[:-1])\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(scaled_data, labels, test_size=0.3, random_state=73)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Convert y labels to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, num_classes=4)\n",
    "y_val_onehot = to_categorical(y_val, num_classes=4)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Define the model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # 4 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=50, batch_size=32)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"train.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Convert y labels to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, num_classes=4)\n",
    "y_val_onehot = to_categorical(y_val, num_classes=4)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Define the model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax') \n",
    "    \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=50, batch_size=32)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"traing-more-norouns.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Convert y labels to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, num_classes=4)\n",
    "y_val_onehot = to_categorical(y_val, num_classes=4)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Define the model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # 4 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=50, batch_size=32)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"dropout.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define the model with L2 regularization\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],), \n",
    "          kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(4, activation='softmax', \n",
    "          kernel_regularizer=regularizers.l2(0.0001))  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss with L2 Regularization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_with_l2_regularization.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model with L2 regularization\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],), \n",
    "          kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(4, activation='softmax', \n",
    "          kernel_regularizer=regularizers.l2(0.0001))  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss with L2 Regularization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_with_l2_regularization.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-adopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('teleCust1000t.csv')\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.iloc[:, :-1])\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=73)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=73)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# Define a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 4)  # Assuming 4 classes for classification\n",
    ")\n",
    "\n",
    "# Ensure the model has a parameters method\n",
    "print(hasattr(model, 'parameters'))  # Should print: True\n",
    "\n",
    "# Use a standard optimizer (e.g., Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(50):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/50], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
